{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDs:\n",
    "Insert yours IDs to the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID #1: 203972922\n",
    "\n",
    "ID #2: 201312907\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the following instructions carefully:\n",
    "\n",
    "1. This jupyter notebook contains all the step by step instructions needed for this exercise.\n",
    "1. You are free to add cells.\n",
    "1. Write your functions and your answers in this jupyter notebook only.\n",
    "1. Answers to theoretical questions should be written in **markdown cells (with $\\LaTeX$ support)**.\n",
    "1. Submit this jupyter notebook only using your ID as a filename. Not to use ZIP or RAR. For example, your Moodle submission file name should look like this (two id numbers): `123456789_987654321.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy import stats\n",
    "from sklearn import mixture\n",
    "from sklearn.datasets import load_boston\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy import stats\n",
    "from sklearn import mixture\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import mixture\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - Data exploration and visialization - practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Boston dataset from sklearn.\n",
    "Explore the data. follow th instructions below and make sure to support your answers with proper outputs and plots.\n",
    "When plotting, pay close attention to the range of the axis, and include axis labels and a title for the figure.\n",
    "\n",
    "1. describe the dataset. How many samples does it contain? How many features? What isis the data type for each variable?\n",
    "2. Produce a histogram and a boxplot of the nitric oxides concentration. describe the distribution.\n",
    "3. Produce a correlation matrix of all the features. Are there any correlated features? Can you identify one feature with unusual behaviour?\n",
    "4. Select the 2 pairs of features with the highest correlation (positive or negative) and plot 2 scatter plots with marginal histograms (JointPlot). \n",
    "5. Produce a cumulative histogram of the age variable and add two horizontal lines on the first and third quartile (on the cumulative count)\n",
    "6. Identify and report 2 “interesting” trends in the data. No need to provide statistical confidence at this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "X = boston.data\n",
    "columns = list(boston.feature_names)\n",
    "y = boston.target\n",
    "boston_df = pd.DataFrame(np.concatenate((X, y[:, np.newaxis]), axis=1), \\\n",
    "                         columns= columns + ['PRICE'])\n",
    "print(boston_df.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boston = load_boston()\n",
    "\n",
    "X = boston.data\n",
    "columns = list(boston.feature_names)\n",
    "y = boston.target\n",
    "boston_df = pd.DataFrame(np.concatenate((X, y[:, np.newaxis]), axis=1), \\\n",
    "                         columns= columns + ['PRICE'])\n",
    "print(boston_df.to_markdown())### Question 2 - Independence and conditional independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. describe the dataset. How many samples does it contain? \n",
    "#   How many features? What isis the data type for each variable?\n",
    "\n",
    "#\n",
    "amount_of_feature = boston_df.shape[1]-1\n",
    "amount_of_sampels = boston_df.shape[0]\n",
    "print('The amount of sampels is: ' + str(amount_of_sampels))\n",
    "print('The amount of feature is: ' + str(amount_of_feature))\n",
    "print('data type for each feature:')\n",
    "boston_df.info(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#2. Produce a histogram and a boxplot of the nitric oxides concentration. \n",
    "#   describe the distribution.\n",
    "boston_df_col = boston_df.columns.to_numpy()\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.histplot(x=\"NOX\", data=boston_df)\n",
    "plt.title('histogram plot of NOX feature')\n",
    "plt.grid()\n",
    "NOX_feature = boston_df['NOX'].to_list()\n",
    "plt.axvline(x = 0.44, color= 'r')\n",
    "plt.axvline(x = 0.66, color= 'r')\n",
    "\n",
    "np.mean(NOX_feature)\n",
    "np.std(NOX_feature)\n",
    "np.median(NOX_feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "we can see from the histogram plot that most of the data in the range \n",
    "of [mean-std,mean+std]\n",
    "in our case the mean is 0.55 and the std is 0.11 -> [0.44,0.66]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = sns.boxplot(x=\"NOX\", data=boston_df)\n",
    "plt.title('box plot of NOX feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the box plot show the precentiles:\n",
    "    1. the first line describe the 0% percentile (the min value)\n",
    "    2. the secound line describe the 25% percentile (Q1)\n",
    "    3. the third line describe the 50% percentile (median) \n",
    "    4. the forth line describe the 75% percentile (Q3) \n",
    "    5. the fivth line describe the 100% percentile (the max value) \n",
    "from our box plot we can infer that the IQR(inter quartile range) is\n",
    "between ~0.44 to ~0.66 which correlate with the histogram conclution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Produce a correlation matrix of all the features. \n",
    "#   [Are there any correlated features?\n",
    "\n",
    "corr_array = boston_df.corr().to_numpy()\n",
    "np.fill_diagonal(corr_array, 0)\n",
    "max_corr_row_col = np.where(corr_array == np.max(corr_array))[0]\n",
    "min_corr_row_col = np.where(corr_array == np.min(corr_array))[0]\n",
    "min_cor_features = boston_df_col[min_corr_row_col].tolist()\n",
    "max_cor_features = boston_df_col[max_corr_row_col].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.heatmap(boston_df.corr(),cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('correlation matrix of all the features.')\n",
    "\n",
    "string = 'the maximum correlation is between each feature with himself in the digonal'\n",
    "print(string)\n",
    "string = 'The min corroletion found to be betwenn feature ' + min_cor_features[0] + ' to feature ' \\\n",
    "+ min_cor_features[1]\n",
    "print(string)\n",
    "\n",
    "string = 'The max corroletion found to be betwenn feature ' + max_cor_features[0] + ' to feature ' \\\n",
    "+ max_cor_features[1]\n",
    "print(string)\n",
    "\n",
    "string = 'The unusual feature is the CHAS, it can be seen from the heat map,' + \\\n",
    "        'that he has no correlation with other features'\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Select the 2 pairs of features with the highest correlation\n",
    "# (positive or negative) and plot 2 scatter plots with marginal histograms (JointPlot). \n",
    "\n",
    "\n",
    "\n",
    "ax= sns.jointplot(x=boston_df[max_cor_features[0]], y=boston_df[max_cor_features[1]],\\\n",
    "              marginal_kws=dict(bins=30))\n",
    "ax.fig.suptitle('Joint plot between ' + max_cor_features[0]+ ', '+ max_cor_features[1])\n",
    "\n",
    "ax= sns.jointplot(x=boston_df[min_cor_features[0]], y=boston_df[min_cor_features[1]],\\\n",
    "              marginal_kws=dict(bins=30))\n",
    "ax.fig.suptitle('Joint plot between ' + min_cor_features[0]+ ', '+ min_cor_features[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#5. Produce a cumulative histogram of the age variable and \n",
    "#   add two horizontal lines on the first and third quartile (on the cumulative count)\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.histplot(x=\"AGE\", data=boston_df, cumulative=True, stat='density')\n",
    "plt.title('cumulative histogram plot of AGE feature')\n",
    "cumsum = boston_df['AGE'].to_numpy().cumsum()\n",
    "plt.axhline(y= 0.25, color = 'r')\n",
    "plt.axhline(y= 0.75, color = 'r')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Identify and report 2 “interesting” trends in the data. \n",
    "#   No need to provide statistical confidence at this point. \n",
    "\n",
    "boston_df.plot.scatter(x='RM', y='PRICE')\n",
    "plt.title('Scatter plot\\nThe most positive corrolettion the price')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "boston_df.plot.scatter(x='LSTAT', y='PRICE')\n",
    "plt.title('Scatter plot\\nThe most negative corrolettion the price')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "boston_df.plot.scatter(x='AGE', y='PRICE')\n",
    "plt.title('Scatter plot\\nThe most negative corrolettion the price')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.A\n",
    "Let $\\ X, Y \\ $ and $Z$  be discrete random variables with $\\ n, m \\ $ and $k=2$ possible outcomes respectivley.\n",
    "\n",
    "How many parameters define the joint distribution of $\\ X, Y \\ $ and $Z$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x have n parameters \n",
    "## y have m parameters\n",
    "## z have k parameters\n",
    "   \n",
    "## the amount of parameters of joint distribution is n*m*k-1 in ourcase 2*n*m-1 \n",
    "## the reason for the -1, is the complete of joint distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.B\n",
    "For the same random variables from the previous section, how many parameters define the joint distribution of $\\ X, Y \\ $ and $Z$ if we now know that they are independent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x,y,z are iid, therefore each random variable have his amount of parameters -1\n",
    "\n",
    "## x have n-1\n",
    "## y have m-1\n",
    "## z have k-1\n",
    "\n",
    "## which is in our case n-1+m-1+2-1 = n+m-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.C\n",
    "For the same random variables from the previous section, how many parameters define the joint distribution of $\\ X, Y \\ $ and $Z$ if we now know that $X$ and $Y$ are conditionaly independent given $Z$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x,y are conditionaly independent to z, therefore \n",
    "## P(x,y,z) = P(z)*P(y|z)*P(x|y,z) = P(z)*P(y|z)*P(x|z)\n",
    "\n",
    "## that mean the amount of parameters is k+k*(m-1)+k*(n-1) \n",
    "## in our case 2+2*(m-1) + 2*(n-1)  = 2m+2n-2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.D\n",
    "Give an example for a joint distribution of $\\ X, Y \\ $ and $Z$ where $X$ and $Y$ are NOT conditionally independent given $Z$, but $X$ and $Y$ are (unconditionally) independent.\n",
    "\n",
    "Where $X$ and $Y$ are standard normal distribution ($N(0, 1)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 - Gaussian mixtures – parameter estimation and generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the data provided in GMD_2021.csv\n",
    "Assume that the data comes from a Gaussian mixture distribution (GMD) with $k=3$. Furthermore, assume that $\\mu_{1}=4, \\mu_{2}=9, \\sigma_{1}=\\sigma_{2}=0.5, \\sigma_3=1.5$ and $w_2=0.25$.\n",
    "\n",
    "Read the data and answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.A\n",
    "Provide an estimate for the other parameters of the distribution in two different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## way 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== WAY no' 1 using Gaussian mixture with EM ====================\n",
      "       Means  Weights\n",
      "0   4.083811    0.125\n",
      "1   8.997480    0.250\n",
      "2  15.102616    0.625\n"
     ]
    }
   ],
   "source": [
    "GMD_csv_df = pd.read_csv(r\"C:\\Msc\\Git\\StatisticsAndDataAnalysis\\HW2\\GMD_2021.csv\", header=None, index_col=0)\n",
    "samples = GMD_csv_df[1].to_list()\n",
    "\n",
    "#print(df_gmd.head())\n",
    "mue_1 = 4\n",
    "mue_2 = 9\n",
    "sigma_1 = 0.5\n",
    "sigma_2 = 0.5\n",
    "sigma_3 = 1.5\n",
    "\n",
    "######## way 1 #####\n",
    "mean_init_array = np.array([[mue_1],[mue_2],[np.mean(samples)]])\n",
    "weight_2 = 0.25\n",
    "weight_init = (0.25,weight_2,0.5)\n",
    "### WAY no' 1 - Using Gaussian mixture with EM ###\n",
    "print(\"=\"*20,\"WAY no' 1 using Gaussian mixture with EM\",\"=\"*20)\n",
    "# Fit a Gaussian mixture with EM using 2 components\n",
    "gmm = mixture.GaussianMixture(n_components=3,means_init =mean_init_array ,weights_init=weight_init,  covariance_type='full').fit(GMD_csv_df)\n",
    "\n",
    "GM_result_df = pd.DataFrame()\n",
    "GM_result_df['Means'] = gmm.means_.reshape(3,).tolist()\n",
    "GM_result_df['Weights'] =np.round( gmm.weights_.tolist(),3)\n",
    "print(GM_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## way 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_max= 0\n",
    "new_parameters = [0,0,0]\n",
    "\n",
    "for w1 in np.arange(0.05,0.75,0.05):\n",
    "    w3 = 1-w1-weight_2\n",
    "    for mue_3 in range (1,50):\n",
    "        curr_list = [w1,w3,mue_3]\n",
    "        curr_sum = 0\n",
    "        for i_sample in samples:\n",
    "            curr_sum += (w1*scipy.stats.norm(mue_1,sigma_1 ).pdf(i_sample)+weight_2*scipy.stats.norm(mue_2,sigma_2 ).pdf(i_sample)+w3*scipy.stats.norm(mue_3,sigma_3 ).pdf(i_sample))\n",
    "        if new_max<curr_sum:\n",
    "            new_parameters = curr_list\n",
    "            new_max  = curr_sum\n",
    "            \n",
    "            \n",
    "List = [[mue_1, new_parameters[1]], [mue_2, weight_2], [new_parameters[2], new_parameters[1]]]\n",
    "GM_result_df = pd.DataFrame(List, columns = ['Means', 'Weights'])\n",
    "print(GM_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.B\n",
    "Plot a graph of the pdf of the distribution you inferred. Select adequate limits for the axes for this plot and explain your decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#### 3.B\n",
    "Plot a graph of the pdf of the distribution you inferred.\n",
    " Select adequate limits for the axes for this plot and explain your decision.\n",
    "\"\"\"\n",
    "#fff\n",
    "\n",
    "sns.distplot(samples,bins=50)\n",
    "std = np.std(samples)\n",
    "mean = np.mean(samples)\n",
    "plt.xlim(xmin= mean-3*std , xmax= mean+3*std)\n",
    "# The limits are where the cdf is 0.997 by the formula : P(μ-3s ≤ Y ≤ μ+3s) \n",
    "plt.grid()\n",
    "plt.xlabel(f'Sample Values')\n",
    "plt.title(f'PDF GMD_2021 Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "#### 3.C\n",
    "Now assume that the data comes from a Gaussian mixture \n",
    "distribution (GMD) with $k=4$.\n",
    "\n",
    "The given data and parameters stay the same.\n",
    "\n",
    "Can you estimate the unknown parameters in the two ways\n",
    "described in section A? Explain.\n",
    "\"\"\"\n",
    "# 55\n",
    "\n",
    "mean_init_array = np.array([[mue_1],[mue_2],[np.mean(samples)],[np.mean(samples)]])\n",
    "weight_2 = 0.25\n",
    "weight_init = (0.25,weight_2,0.25,0.25)\n",
    "### WAY no' 1 - Using Gaussian mixture with EM ###\n",
    "print(\"=\"*20,\"WAY no' 1 using Gaussian mixture with EM\",\"=\"*20)\n",
    "# Fit a Gaussian mixture with EM using 2 components\n",
    "gmm = mixture.GaussianMixture(n_components=4,means_init =mean_init_array ,weights_init=weight_init,  covariance_type='full').fit(GMD_csv_df)\n",
    "\n",
    "GM_result_df = pd.DataFrame()\n",
    "GM_result_df['Means'] = gmm.means_.reshape(4,).tolist()\n",
    "GM_result_df['Weights'] =np.round( gmm.weights_.tolist(),3)\n",
    "print(GM_result_df)#### 3.C\n",
    "Now assume that the data comes from a Gaussian mixture distribution (GMD) with $k=4$.\n",
    "\n",
    "The given data and parameters stay the same.\n",
    "\n",
    "Can you estimate the unknown parameters in the two ways described in section A? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#### 3.C\n",
    "Now assume that the data comes from a Gaussian mixture \n",
    "distribution (GMD) with $k=4$.\n",
    "\n",
    "The given data and parameters stay the same.\n",
    "\n",
    "Can you estimate the unknown parameters in the two ways\n",
    "described in section A? Explain.\n",
    "\"\"\"\n",
    "# 55\n",
    "\n",
    "mean_init_array = np.array([[mue_1],[mue_2],[np.mean(samples)],[np.mean(samples)]])\n",
    "weight_2 = 0.25\n",
    "weight_init = (0.25,weight_2,0.25,0.25)\n",
    "### WAY no' 1 - Using Gaussian mixture with EM ###\n",
    "print(\"=\"*20,\"WAY no' 1 using Gaussian mixture with EM\",\"=\"*20)\n",
    "# Fit a Gaussian mixture with EM using 2 components\n",
    "gmm = mixture.GaussianMixture(n_components=4,means_init =mean_init_array ,weights_init=weight_init,  covariance_type='full').fit(GMD_csv_df)\n",
    "\n",
    "GM_result_df = pd.DataFrame()\n",
    "GM_result_df['Means'] = gmm.means_.reshape(4,).tolist()\n",
    "GM_result_df['Weights'] =np.round( gmm.weights_.tolist(),3)\n",
    "print(GM_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.D\n",
    "Describe two ways for generating data for a GMM random variable with:\n",
    "* centers at  $\\mu_1=3, \\mu_2=7, \\mu_3=10$\n",
    "* $\\sigma_1=\\sigma_2=\\sigma_3=1$\n",
    "* $w_1=w_2=w_3=0.33$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLike we did in the first question-\\n1. create a normal distrubution to each geonosian with size of N\\n2. create an empty GMD array\\n3. do N times:\\n    - randomize a P(probability) that considerate the weight of each distrubution\\n    - add to the GMD array a value from one of the normal distrubution\\n    \\n#### way 2\\n1. Genarate 2 normal distrubution with size of 500\\n2. join  the 2 vectors into one which represent the GMD\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Like we did in the first question-\n",
    "1. create a normal distrubution to each geonosian with size of N\n",
    "2. create an empty GMD array\n",
    "3. do N times:\n",
    "    - randomize a P(probability) that considerate the weight of each distrubution\n",
    "    - add to the GMD array a value from one of the normal distrubution\n",
    "    \n",
    "#### way 2\n",
    "1. Genarate 2 normal distrubution with size of 500\n",
    "2. join  the 2 vectors into one which represent the GMD\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.E\n",
    "Use one of the above approaches to generate 1000 points and plot a histogram of the result (decide on bins, axes etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mue1 = 3\n",
    "mue2 = 7\n",
    "mue3 = 10\n",
    "sigma1 = sigma2 = sigma3 = 1\n",
    "w1 = w2 = w3 = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "numpy.random.seed(0x5eed)\n",
    "# Parameters of the mixture components\n",
    "norm_params = np.array([[mue1, sigma1],\n",
    "                        [mue2, sigma2],\n",
    "                        [mue3, sigma3]])\n",
    "n_components = norm_params.shape[0]\n",
    "# Weight of each component, in this case all of them are 1/3\n",
    "weights = np.ones(n_components, dtype=np.float64) / 3.0\n",
    "# A stream of indices from which to choose the component\n",
    "mixture_idx = numpy.random.choice(len(weights), size=n, replace=True, p=weights)\n",
    "# y is the mixture sample\n",
    "y = numpy.fromiter((ss.norm.rvs(*(norm_params[i])) for i in mixture_idx),\n",
    "                   dtype=np.float64)\n",
    "\n",
    "# Theoretical PDF plotting -- generate the x and y plotting positions\n",
    "xs = np.linspace(y.min(), y.max(), 200)\n",
    "ys = np.zeros_like(xs)\n",
    "\n",
    "for (l, s), w in zip(norm_params, weights):\n",
    "    ys += ss.norm.pdf(xs, loc=l, scale=s) * w\n",
    "\n",
    "sns.distplot(y,bins=100)\n",
    "plt.title('way A  - to create GMD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.F\n",
    "Use the other one to generate 1000 more points and draw two comparative histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "norm1 = np.random.normal(mue1, sigma1,1000)\n",
    "norm2 = np.random.normal(mue2, sigma2,1000)\n",
    "norm3 = np.random.normal(mue3, sigma3,1000)\n",
    "\n",
    "new_norm2 = []\n",
    "new_norm2.extend(norm1)\n",
    "new_norm2.extend(norm2)\n",
    "new_norm2.extend(norm3)\n",
    "sns.distplot(new_norm2, bins=100)\n",
    "plt.title('way B  - to create GMD')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 - Normally distributed salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The annual salaries of employees in a large Randomistan company are approximateley normally distributed with a mean of 70,000 RCU and a standard deviation of 30,000 RCU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.A\n",
    "What percent of people earn less than 50,000 RCU?\n",
    "\"\"\"\n",
    "\n",
    "mean = 70000\n",
    "std = 30000\n",
    "desire_sallary = 50000\n",
    "less_than_50k = scipy.stats.norm(mean,std).cdf(desire_sallary)\n",
    "\n",
    "#### 4.A\n",
    "What percent of people earn less than 50,000 RCU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2524925375469229\n"
     ]
    }
   ],
   "source": [
    "mean = 70000\n",
    "std = 30000\n",
    "desire_sallary = 50000\n",
    "less_than_50k = scipy.stats.norm(mean,std).cdf(desire_sallary)\n",
    "print(less_than_50k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.B\n",
    "What percent of people earn between 45,000 RCU and 65,000 RCU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_desire_sallary = 65000\n",
    "down_desire_sallary = 45000\n",
    "\n",
    "up_cdf_result = scipy.stats.norm(mean,std).cdf(up_desire_sallary)\n",
    "down_cdf_result = scipy.stats.norm(mean,std).cdf(down_desire_sallary)\n",
    "\n",
    "percent_to_sallary_between_2_values = up_cdf_result - down_cdf_result\n",
    "\n",
    "print(percent_to_sallary_between_2_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more_than_desire_sallary = 70000\n",
    "\n",
    "percent_more_than_desire_sallary = 1-scipy.stats.norm(mean,std).cdf(more_than_desire_sallary)\n",
    "\n",
    "#### 4.C\n",
    "What percent of people earn more than 70,000 RCU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_desire_sallary = 70000\n",
    "\n",
    "percent_more_than_desire_sallary = 1-scipy.stats.norm(mean,std).cdf(more_than_desire_sallary)\n",
    "\n",
    "print(percent_more_than_desire_sallary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more_than_desire_sallary = 140000\n",
    "amount_of_employees = 1000\n",
    "percent_more_than_desire_sallary = 1-scipy.stats.norm(mean,std).cdf(more_than_desire_sallary)\n",
    "desire_amount_of_employees = np.ceil(amount_of_employees*percent_more_than_desire_sallary)\n",
    "#### 4.D\n",
    "The company has 1000 employees. How many employees in the company do you expect to earn more than 140,000 RCU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_desire_sallary = 140000\n",
    "amount_of_employees = 1000\n",
    "percent_more_than_desire_sallary = 1-scipy.stats.norm(mean,std).cdf(more_than_desire_sallary)\n",
    "desire_amount_of_employees = np.ceil(amount_of_employees*percent_more_than_desire_sallary)\n",
    "print(desire_amount_of_employees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 - Coupon collector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $T_{N}$ denote the waiting time for full single coupon collection with N different equiprobable coupon types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.A\n",
    "Write code to compute the exact value of $E(T_{N})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the lecture:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\operatorname{E}(T)  = n \\cdot H_n \\sim  n \\cdot ln(n)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find N-th Harmonic Number  . taken from https://www.geeksforgeeks.org/program-to-find-the-nth-harmonic-number/\n",
    "def nthHarmonic(N) : \n",
    "    # H1 = 1  \n",
    "    harmonic = 1.00\n",
    "    # loop to apply the forumula  \n",
    "    # Hn = H1 + H2 + H3 ... +  \n",
    "    # Hn-1 + Hn-1 + 1/n  \n",
    "    for i in range(2, N + 1) : \n",
    "        harmonic += 1 / i \n",
    "    return harmonic \n",
    "\n",
    "def mean(N):\n",
    "    return N*nthHarmonic(N);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def expectency(N):\n",
    "    return N* np.log(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518.737751763962\n",
      "460.51701859880916\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "print(mean(N))\n",
    "print(expectency(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.B\n",
    "Write code to compute the exact value of $V(T_{N})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ V(T_{N})= \\sum_{i=1}^{n} Var(x_{i}) $$\n",
    "\n",
    "if $ X_i \\sim GEO(p_i=(N-i+1)/N) $   then:\n",
    "\n",
    "$$ V(T_{N})= \\sum_{i=1}^{n} Var(x_{i}) = ... = n^2 \\cdot \\Sigma ((1/i^2) - n \\cdot H(n)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def var(N):\n",
    "    sum = 0\n",
    "    for i in range(1,N+1):\n",
    "        p = (N-i+1)/N\n",
    "        sum += stats.geom.var(p)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\or livne\\anaconda\\lib\\site-packages\\scipy\\stats\\_discrete_distns.py:375: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  g1 = (2.0-p) / sqrt(qr)\n",
      "C:\\Users\\or livne\\anaconda\\lib\\site-packages\\scipy\\stats\\_discrete_distns.py:376: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  g2 = np.polyval([1, -6, 6], p)/(1.0-p)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15831.101250084967"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "var(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.C\n",
    "Write code to exactly compute $P(T_{30}>60)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probLarger(succ,tries):\n",
    "    from scipy.stats import geom\n",
    "    \n",
    "    p = (succ - np.arange(succ)) / succ\n",
    "    \n",
    "    try_vec = np.arange(tries) + 1\n",
    "    p1 = geom.pmf(try_vec, p[0])\n",
    "    \n",
    "    for current in p[1:]:\n",
    "        p_i = geom.pmf(try_vec, current)\n",
    "        p1 = np.convolve(p1, p_i)\n",
    "    \n",
    "    return 1 - p1[:tries+1-succ].sum()\n",
    "\n",
    "print(round(probLarger(20,40),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.D\n",
    "Use Chebicheff to provide a bound for the probability from C and compare the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
